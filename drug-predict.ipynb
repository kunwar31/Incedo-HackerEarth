{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/dataset2147b1d/train_file.csv')\n",
    "test = pd.read_csv('../input/dataset2147b1d/test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Subtopic','Greater_Risk_Question','Description','Sex','Race','Grade','QuestionCode','StratID1','StratID2','StratID3','StratificationType','YEAR','LocationDesc']\n",
    "for col in columns:\n",
    "    rev = lambda x : {v:k for k,v in x.items()}\n",
    "    index = rev(dict(enumerate(list(train[col].value_counts().keys()))))\n",
    "    train[col] = train[col].apply(lambda x : index[x])\n",
    "    test[col] = test[col].apply(lambda x : index[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Subtopic','Description','Sex','Race','Grade','StratID1','StratID2','StratID3','StratificationType','Sample_Size','YEAR','LocationDesc']]\n",
    "Y = train['Greater_Risk_Probability']\n",
    "x_test = test[['Subtopic','Description','Sex','Race','Grade','StratID1','StratID2','StratID3','StratificationType','Sample_Size','YEAR','LocationDesc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"min_data_in_leaf\": 0,\n",
    "    \"bagging_seed\" : 1234,\n",
    "    \"verbosity\" : 1,\n",
    "    \"lambda_l2\" : 5.0,\n",
    "    \"seed\": 1234,\n",
    "    \"drop_rate\" : 0.5,\n",
    "    \"min_data_per_group\":1,\n",
    "    \"max_bin\" : 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41899\tvalid_1's rmse: 4.33927\n",
      "[2000]\ttraining's rmse: 2.91249\tvalid_1's rmse: 4.19607\n",
      "[3000]\ttraining's rmse: 2.58532\tvalid_1's rmse: 4.13735\n",
      "[4000]\ttraining's rmse: 2.33052\tvalid_1's rmse: 4.10213\n",
      "[5000]\ttraining's rmse: 2.13077\tvalid_1's rmse: 4.08418\n",
      "[6000]\ttraining's rmse: 1.95725\tvalid_1's rmse: 4.06864\n",
      "[7000]\ttraining's rmse: 1.80928\tvalid_1's rmse: 4.06024\n",
      "[8000]\ttraining's rmse: 1.68172\tvalid_1's rmse: 4.05364\n",
      "[9000]\ttraining's rmse: 1.56988\tvalid_1's rmse: 4.04633\n",
      "[10000]\ttraining's rmse: 1.46785\tvalid_1's rmse: 4.0456\n",
      "[11000]\ttraining's rmse: 1.37698\tvalid_1's rmse: 4.04159\n",
      "[12000]\ttraining's rmse: 1.29406\tvalid_1's rmse: 4.04174\n",
      "[13000]\ttraining's rmse: 1.21893\tvalid_1's rmse: 4.03997\n",
      "[14000]\ttraining's rmse: 1.14994\tvalid_1's rmse: 4.03836\n",
      "[15000]\ttraining's rmse: 1.08695\tvalid_1's rmse: 4.0396\n",
      "[16000]\ttraining's rmse: 1.03019\tvalid_1's rmse: 4.04063\n",
      "[17000]\ttraining's rmse: 0.976939\tvalid_1's rmse: 4.04483\n",
      "Early stopping, best iteration is:\n",
      "[14130]\ttraining's rmse: 1.1414\tvalid_1's rmse: 4.03705\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.43161\tvalid_1's rmse: 4.15292\n",
      "[2000]\ttraining's rmse: 2.92609\tvalid_1's rmse: 4.01376\n",
      "[3000]\ttraining's rmse: 2.5959\tvalid_1's rmse: 3.95362\n",
      "[4000]\ttraining's rmse: 2.33659\tvalid_1's rmse: 3.92244\n",
      "[5000]\ttraining's rmse: 2.13287\tvalid_1's rmse: 3.9101\n",
      "[6000]\ttraining's rmse: 1.9541\tvalid_1's rmse: 3.90564\n",
      "[7000]\ttraining's rmse: 1.80512\tvalid_1's rmse: 3.90302\n",
      "[8000]\ttraining's rmse: 1.67882\tvalid_1's rmse: 3.9029\n",
      "[9000]\ttraining's rmse: 1.56374\tvalid_1's rmse: 3.89924\n",
      "[10000]\ttraining's rmse: 1.45942\tvalid_1's rmse: 3.90532\n",
      "[11000]\ttraining's rmse: 1.36773\tvalid_1's rmse: 3.90626\n",
      "[12000]\ttraining's rmse: 1.28505\tvalid_1's rmse: 3.90684\n",
      "Early stopping, best iteration is:\n",
      "[9216]\ttraining's rmse: 1.54102\tvalid_1's rmse: 3.89788\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.42222\tvalid_1's rmse: 4.08795\n",
      "[2000]\ttraining's rmse: 2.92484\tvalid_1's rmse: 3.9568\n",
      "[3000]\ttraining's rmse: 2.60727\tvalid_1's rmse: 3.8925\n",
      "[4000]\ttraining's rmse: 2.35631\tvalid_1's rmse: 3.86089\n",
      "[5000]\ttraining's rmse: 2.14672\tvalid_1's rmse: 3.84399\n",
      "[6000]\ttraining's rmse: 1.96939\tvalid_1's rmse: 3.82825\n",
      "[7000]\ttraining's rmse: 1.82343\tvalid_1's rmse: 3.82573\n",
      "[8000]\ttraining's rmse: 1.6901\tvalid_1's rmse: 3.81698\n",
      "[9000]\ttraining's rmse: 1.57557\tvalid_1's rmse: 3.80929\n",
      "[10000]\ttraining's rmse: 1.47241\tvalid_1's rmse: 3.80425\n",
      "[11000]\ttraining's rmse: 1.38286\tvalid_1's rmse: 3.80365\n",
      "[12000]\ttraining's rmse: 1.29983\tvalid_1's rmse: 3.79921\n",
      "[13000]\ttraining's rmse: 1.22208\tvalid_1's rmse: 3.79905\n",
      "[14000]\ttraining's rmse: 1.1528\tvalid_1's rmse: 3.79494\n",
      "[15000]\ttraining's rmse: 1.08974\tvalid_1's rmse: 3.79321\n",
      "[16000]\ttraining's rmse: 1.03033\tvalid_1's rmse: 3.79193\n",
      "[17000]\ttraining's rmse: 0.976648\tvalid_1's rmse: 3.79296\n",
      "[18000]\ttraining's rmse: 0.927051\tvalid_1's rmse: 3.79377\n",
      "Early stopping, best iteration is:\n",
      "[15817]\ttraining's rmse: 1.04134\tvalid_1's rmse: 3.79106\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41905\tvalid_1's rmse: 4.29848\n",
      "[2000]\ttraining's rmse: 2.92566\tvalid_1's rmse: 4.16223\n",
      "[3000]\ttraining's rmse: 2.59489\tvalid_1's rmse: 4.0845\n",
      "[4000]\ttraining's rmse: 2.33943\tvalid_1's rmse: 4.03486\n",
      "[5000]\ttraining's rmse: 2.12762\tvalid_1's rmse: 4.00185\n",
      "[6000]\ttraining's rmse: 1.95713\tvalid_1's rmse: 3.98505\n",
      "[7000]\ttraining's rmse: 1.8111\tvalid_1's rmse: 3.97467\n",
      "[8000]\ttraining's rmse: 1.68178\tvalid_1's rmse: 3.96826\n",
      "[9000]\ttraining's rmse: 1.56629\tvalid_1's rmse: 3.96376\n",
      "[10000]\ttraining's rmse: 1.46301\tvalid_1's rmse: 3.96219\n",
      "[11000]\ttraining's rmse: 1.37079\tvalid_1's rmse: 3.95858\n",
      "[12000]\ttraining's rmse: 1.28859\tvalid_1's rmse: 3.9588\n",
      "[13000]\ttraining's rmse: 1.21349\tvalid_1's rmse: 3.96076\n",
      "[14000]\ttraining's rmse: 1.14488\tvalid_1's rmse: 3.96515\n",
      "Early stopping, best iteration is:\n",
      "[11669]\ttraining's rmse: 1.31445\tvalid_1's rmse: 3.95717\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.43391\tvalid_1's rmse: 4.12456\n",
      "[2000]\ttraining's rmse: 2.92243\tvalid_1's rmse: 4.0044\n",
      "[3000]\ttraining's rmse: 2.58504\tvalid_1's rmse: 3.95016\n",
      "[4000]\ttraining's rmse: 2.33353\tvalid_1's rmse: 3.91604\n",
      "[5000]\ttraining's rmse: 2.12385\tvalid_1's rmse: 3.89885\n",
      "[6000]\ttraining's rmse: 1.95171\tvalid_1's rmse: 3.88656\n",
      "[7000]\ttraining's rmse: 1.80307\tvalid_1's rmse: 3.88213\n",
      "[8000]\ttraining's rmse: 1.67266\tvalid_1's rmse: 3.87688\n",
      "[9000]\ttraining's rmse: 1.558\tvalid_1's rmse: 3.87136\n",
      "[10000]\ttraining's rmse: 1.45509\tvalid_1's rmse: 3.8699\n",
      "[11000]\ttraining's rmse: 1.36498\tvalid_1's rmse: 3.87035\n",
      "[12000]\ttraining's rmse: 1.28261\tvalid_1's rmse: 3.87207\n",
      "[13000]\ttraining's rmse: 1.2077\tvalid_1's rmse: 3.87459\n",
      "[14000]\ttraining's rmse: 1.14057\tvalid_1's rmse: 3.87641\n",
      "Early stopping, best iteration is:\n",
      "[11154]\ttraining's rmse: 1.35144\tvalid_1's rmse: 3.86902\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41935\tvalid_1's rmse: 4.17986\n",
      "[2000]\ttraining's rmse: 2.91403\tvalid_1's rmse: 4.05193\n",
      "[3000]\ttraining's rmse: 2.57722\tvalid_1's rmse: 3.98874\n",
      "[4000]\ttraining's rmse: 2.32503\tvalid_1's rmse: 3.96011\n",
      "[5000]\ttraining's rmse: 2.12671\tvalid_1's rmse: 3.94264\n",
      "[6000]\ttraining's rmse: 1.95525\tvalid_1's rmse: 3.92722\n",
      "[7000]\ttraining's rmse: 1.8069\tvalid_1's rmse: 3.92131\n",
      "[8000]\ttraining's rmse: 1.67551\tvalid_1's rmse: 3.91575\n",
      "[9000]\ttraining's rmse: 1.56303\tvalid_1's rmse: 3.91401\n",
      "[10000]\ttraining's rmse: 1.46375\tvalid_1's rmse: 3.91341\n",
      "[11000]\ttraining's rmse: 1.37192\tvalid_1's rmse: 3.91308\n",
      "[12000]\ttraining's rmse: 1.28979\tvalid_1's rmse: 3.9114\n",
      "[13000]\ttraining's rmse: 1.21648\tvalid_1's rmse: 3.9162\n",
      "[14000]\ttraining's rmse: 1.14677\tvalid_1's rmse: 3.91784\n",
      "Early stopping, best iteration is:\n",
      "[11876]\ttraining's rmse: 1.29984\tvalid_1's rmse: 3.91094\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41598\tvalid_1's rmse: 4.05102\n",
      "[2000]\ttraining's rmse: 2.91542\tvalid_1's rmse: 3.93245\n",
      "[3000]\ttraining's rmse: 2.58668\tvalid_1's rmse: 3.86678\n",
      "[4000]\ttraining's rmse: 2.33414\tvalid_1's rmse: 3.82974\n",
      "[5000]\ttraining's rmse: 2.12833\tvalid_1's rmse: 3.80865\n",
      "[6000]\ttraining's rmse: 1.95242\tvalid_1's rmse: 3.80197\n",
      "[7000]\ttraining's rmse: 1.8066\tvalid_1's rmse: 3.797\n",
      "[8000]\ttraining's rmse: 1.67895\tvalid_1's rmse: 3.7901\n",
      "[9000]\ttraining's rmse: 1.56526\tvalid_1's rmse: 3.78417\n",
      "[10000]\ttraining's rmse: 1.4658\tvalid_1's rmse: 3.78443\n",
      "[11000]\ttraining's rmse: 1.3725\tvalid_1's rmse: 3.78327\n",
      "[12000]\ttraining's rmse: 1.28879\tvalid_1's rmse: 3.78364\n",
      "Early stopping, best iteration is:\n",
      "[9131]\ttraining's rmse: 1.55069\tvalid_1's rmse: 3.78234\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.42347\tvalid_1's rmse: 4.12182\n",
      "[2000]\ttraining's rmse: 2.91018\tvalid_1's rmse: 3.99864\n",
      "[3000]\ttraining's rmse: 2.57316\tvalid_1's rmse: 3.95041\n",
      "[4000]\ttraining's rmse: 2.31994\tvalid_1's rmse: 3.92549\n",
      "[5000]\ttraining's rmse: 2.1166\tvalid_1's rmse: 3.91515\n",
      "[6000]\ttraining's rmse: 1.94391\tvalid_1's rmse: 3.90677\n",
      "[7000]\ttraining's rmse: 1.79287\tvalid_1's rmse: 3.90165\n",
      "[8000]\ttraining's rmse: 1.66149\tvalid_1's rmse: 3.8981\n",
      "[9000]\ttraining's rmse: 1.55028\tvalid_1's rmse: 3.89886\n",
      "[10000]\ttraining's rmse: 1.45038\tvalid_1's rmse: 3.90121\n",
      "Early stopping, best iteration is:\n",
      "[7692]\ttraining's rmse: 1.6993\tvalid_1's rmse: 3.89509\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.42814\tvalid_1's rmse: 4.05998\n",
      "[2000]\ttraining's rmse: 2.92482\tvalid_1's rmse: 3.9036\n",
      "[3000]\ttraining's rmse: 2.59075\tvalid_1's rmse: 3.83422\n",
      "[4000]\ttraining's rmse: 2.33005\tvalid_1's rmse: 3.80256\n",
      "[5000]\ttraining's rmse: 2.12342\tvalid_1's rmse: 3.77938\n",
      "[6000]\ttraining's rmse: 1.95569\tvalid_1's rmse: 3.76477\n",
      "[7000]\ttraining's rmse: 1.80764\tvalid_1's rmse: 3.76176\n",
      "[8000]\ttraining's rmse: 1.67561\tvalid_1's rmse: 3.75727\n",
      "[9000]\ttraining's rmse: 1.56096\tvalid_1's rmse: 3.75806\n",
      "[10000]\ttraining's rmse: 1.45985\tvalid_1's rmse: 3.75352\n",
      "[11000]\ttraining's rmse: 1.36983\tvalid_1's rmse: 3.7519\n",
      "[12000]\ttraining's rmse: 1.28878\tvalid_1's rmse: 3.75232\n",
      "[13000]\ttraining's rmse: 1.21407\tvalid_1's rmse: 3.74844\n",
      "[14000]\ttraining's rmse: 1.14563\tvalid_1's rmse: 3.74737\n",
      "[15000]\ttraining's rmse: 1.08282\tvalid_1's rmse: 3.74629\n",
      "[16000]\ttraining's rmse: 1.0252\tvalid_1's rmse: 3.74663\n",
      "[17000]\ttraining's rmse: 0.970077\tvalid_1's rmse: 3.74816\n",
      "[18000]\ttraining's rmse: 0.920795\tvalid_1's rmse: 3.75023\n",
      "Early stopping, best iteration is:\n",
      "[15516]\ttraining's rmse: 1.0521\tvalid_1's rmse: 3.74457\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.43659\tvalid_1's rmse: 4.16806\n",
      "[2000]\ttraining's rmse: 2.9316\tvalid_1's rmse: 4.05346\n",
      "[3000]\ttraining's rmse: 2.59764\tvalid_1's rmse: 4.00911\n",
      "[4000]\ttraining's rmse: 2.34062\tvalid_1's rmse: 3.99217\n",
      "[5000]\ttraining's rmse: 2.13123\tvalid_1's rmse: 3.97871\n",
      "[6000]\ttraining's rmse: 1.96191\tvalid_1's rmse: 3.97713\n",
      "[7000]\ttraining's rmse: 1.81263\tvalid_1's rmse: 3.96682\n",
      "[8000]\ttraining's rmse: 1.68457\tvalid_1's rmse: 3.96792\n",
      "[9000]\ttraining's rmse: 1.56886\tvalid_1's rmse: 3.97283\n",
      "Early stopping, best iteration is:\n",
      "[6813]\ttraining's rmse: 1.83948\tvalid_1's rmse: 3.96594\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41362\tvalid_1's rmse: 4.29\n",
      "[2000]\ttraining's rmse: 2.91908\tvalid_1's rmse: 4.13685\n",
      "[3000]\ttraining's rmse: 2.5944\tvalid_1's rmse: 4.0771\n",
      "[4000]\ttraining's rmse: 2.33862\tvalid_1's rmse: 4.04389\n",
      "[5000]\ttraining's rmse: 2.129\tvalid_1's rmse: 4.02066\n",
      "[6000]\ttraining's rmse: 1.95449\tvalid_1's rmse: 4.00558\n",
      "[7000]\ttraining's rmse: 1.80874\tvalid_1's rmse: 4.00197\n",
      "[8000]\ttraining's rmse: 1.68258\tvalid_1's rmse: 4.00066\n",
      "[9000]\ttraining's rmse: 1.5686\tvalid_1's rmse: 3.99618\n",
      "[10000]\ttraining's rmse: 1.46588\tvalid_1's rmse: 3.99375\n",
      "[11000]\ttraining's rmse: 1.37648\tvalid_1's rmse: 3.99488\n",
      "[12000]\ttraining's rmse: 1.29329\tvalid_1's rmse: 3.99754\n",
      "[13000]\ttraining's rmse: 1.21983\tvalid_1's rmse: 3.99859\n",
      "Early stopping, best iteration is:\n",
      "[10443]\ttraining's rmse: 1.42503\tvalid_1's rmse: 3.9914\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41048\tvalid_1's rmse: 4.18744\n",
      "[2000]\ttraining's rmse: 2.92286\tvalid_1's rmse: 4.05317\n",
      "[3000]\ttraining's rmse: 2.59295\tvalid_1's rmse: 3.99959\n",
      "[4000]\ttraining's rmse: 2.32858\tvalid_1's rmse: 3.9651\n",
      "[5000]\ttraining's rmse: 2.12443\tvalid_1's rmse: 3.94208\n",
      "[6000]\ttraining's rmse: 1.94803\tvalid_1's rmse: 3.93151\n",
      "[7000]\ttraining's rmse: 1.80045\tvalid_1's rmse: 3.93044\n",
      "[8000]\ttraining's rmse: 1.67483\tvalid_1's rmse: 3.92461\n",
      "[9000]\ttraining's rmse: 1.55779\tvalid_1's rmse: 3.92328\n",
      "[10000]\ttraining's rmse: 1.45746\tvalid_1's rmse: 3.92312\n",
      "[11000]\ttraining's rmse: 1.36407\tvalid_1's rmse: 3.92078\n",
      "[12000]\ttraining's rmse: 1.28247\tvalid_1's rmse: 3.91911\n",
      "[13000]\ttraining's rmse: 1.20825\tvalid_1's rmse: 3.9184\n",
      "[14000]\ttraining's rmse: 1.14208\tvalid_1's rmse: 3.9201\n",
      "[15000]\ttraining's rmse: 1.07913\tvalid_1's rmse: 3.92169\n",
      "Early stopping, best iteration is:\n",
      "[12559]\ttraining's rmse: 1.23983\tvalid_1's rmse: 3.91743\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.40691\tvalid_1's rmse: 4.12622\n",
      "[2000]\ttraining's rmse: 2.9109\tvalid_1's rmse: 3.98907\n",
      "[3000]\ttraining's rmse: 2.58343\tvalid_1's rmse: 3.93225\n",
      "[4000]\ttraining's rmse: 2.33051\tvalid_1's rmse: 3.89964\n",
      "[5000]\ttraining's rmse: 2.13024\tvalid_1's rmse: 3.88495\n",
      "[6000]\ttraining's rmse: 1.95524\tvalid_1's rmse: 3.86587\n",
      "[7000]\ttraining's rmse: 1.80992\tvalid_1's rmse: 3.86512\n",
      "[8000]\ttraining's rmse: 1.6804\tvalid_1's rmse: 3.8639\n",
      "[9000]\ttraining's rmse: 1.56242\tvalid_1's rmse: 3.86313\n",
      "[10000]\ttraining's rmse: 1.46025\tvalid_1's rmse: 3.8656\n",
      "[11000]\ttraining's rmse: 1.36914\tvalid_1's rmse: 3.86388\n",
      "[12000]\ttraining's rmse: 1.28662\tvalid_1's rmse: 3.86756\n",
      "Early stopping, best iteration is:\n",
      "[9093]\ttraining's rmse: 1.55229\tvalid_1's rmse: 3.86116\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.42815\tvalid_1's rmse: 4.06\n",
      "[2000]\ttraining's rmse: 2.93809\tvalid_1's rmse: 3.94156\n",
      "[3000]\ttraining's rmse: 2.60244\tvalid_1's rmse: 3.88467\n",
      "[4000]\ttraining's rmse: 2.34807\tvalid_1's rmse: 3.85129\n",
      "[5000]\ttraining's rmse: 2.14104\tvalid_1's rmse: 3.83217\n",
      "[6000]\ttraining's rmse: 1.96404\tvalid_1's rmse: 3.81841\n",
      "[7000]\ttraining's rmse: 1.81431\tvalid_1's rmse: 3.80955\n",
      "[8000]\ttraining's rmse: 1.6798\tvalid_1's rmse: 3.80967\n",
      "[9000]\ttraining's rmse: 1.56299\tvalid_1's rmse: 3.8077\n",
      "[10000]\ttraining's rmse: 1.46255\tvalid_1's rmse: 3.80877\n",
      "[11000]\ttraining's rmse: 1.37092\tvalid_1's rmse: 3.81061\n",
      "[12000]\ttraining's rmse: 1.2895\tvalid_1's rmse: 3.81074\n",
      "Early stopping, best iteration is:\n",
      "[9404]\ttraining's rmse: 1.5205\tvalid_1's rmse: 3.80614\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's rmse: 3.41581\tvalid_1's rmse: 4.28444\n",
      "[2000]\ttraining's rmse: 2.91291\tvalid_1's rmse: 4.16927\n",
      "[3000]\ttraining's rmse: 2.58502\tvalid_1's rmse: 4.1239\n",
      "[4000]\ttraining's rmse: 2.3317\tvalid_1's rmse: 4.09113\n",
      "[5000]\ttraining's rmse: 2.12687\tvalid_1's rmse: 4.08283\n",
      "[6000]\ttraining's rmse: 1.95041\tvalid_1's rmse: 4.07322\n",
      "[7000]\ttraining's rmse: 1.80581\tvalid_1's rmse: 4.06329\n",
      "[8000]\ttraining's rmse: 1.6775\tvalid_1's rmse: 4.06357\n",
      "[9000]\ttraining's rmse: 1.56502\tvalid_1's rmse: 4.06048\n",
      "[10000]\ttraining's rmse: 1.46752\tvalid_1's rmse: 4.05882\n",
      "[11000]\ttraining's rmse: 1.3777\tvalid_1's rmse: 4.05704\n",
      "[12000]\ttraining's rmse: 1.29552\tvalid_1's rmse: 4.05827\n",
      "[13000]\ttraining's rmse: 1.2206\tvalid_1's rmse: 4.06292\n",
      "[14000]\ttraining's rmse: 1.15332\tvalid_1's rmse: 4.06531\n",
      "Early stopping, best iteration is:\n",
      "[11810]\ttraining's rmse: 1.31103\tvalid_1's rmse: 4.05497\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=15,shuffle=True,random_state=31)\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for t,v in kf.split(X,Y):\n",
    "    x_train,x_valid,y_train,y_valid = X.iloc[t],X.iloc[v],Y.iloc[t],Y.iloc[v]\n",
    "    lgb_train = lgb.Dataset(x_train,\n",
    "                            label=y_train,\n",
    "                            categorical_feature=['Subtopic','Description','Sex','Race','Grade','StratID1','StratID2','StratID3','StratificationType','YEAR','LocationDesc'])\n",
    "    lgb_valid = lgb.Dataset(x_valid,\n",
    "                            label=y_valid, \n",
    "                            categorical_feature=['Subtopic','Description','Sex','Race','Grade','StratID1','StratID2','StratID3','StratificationType','YEAR','LocationDesc'])\n",
    "    evals_result = {}\n",
    "    lgb_clf = lgb.train(lgb_params,\n",
    "                    lgb_train,\n",
    "                    100000,\n",
    "                    valid_sets = [lgb_train,lgb_valid],\n",
    "                    early_stopping_rounds=3000,\n",
    "                    verbose_eval = 1000,\n",
    "                    evals_result=evals_result\n",
    "                   )\n",
    "    all_preds.append(lgb_clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8cb52062b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "imp = lgb_clf.feature_importance()\n",
    "fet = lgb_clf.feature_name()\n",
    "sns.barplot(x=imp, y=fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.vstack(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(all_preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36932,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Greater_Risk_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55400</td>\n",
       "      <td>59.826614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55401</td>\n",
       "      <td>29.004116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55402</td>\n",
       "      <td>55.252582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55403</td>\n",
       "      <td>18.244876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55404</td>\n",
       "      <td>5.883608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55405</td>\n",
       "      <td>48.089758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55406</td>\n",
       "      <td>8.856620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55407</td>\n",
       "      <td>5.165112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55408</td>\n",
       "      <td>18.210373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55409</td>\n",
       "      <td>8.622976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55410</td>\n",
       "      <td>12.271101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55411</td>\n",
       "      <td>2.896477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55412</td>\n",
       "      <td>7.900046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>55413</td>\n",
       "      <td>6.758299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55414</td>\n",
       "      <td>34.516844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55415</td>\n",
       "      <td>85.055578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55416</td>\n",
       "      <td>44.791375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55417</td>\n",
       "      <td>26.193295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>55418</td>\n",
       "      <td>14.011161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55419</td>\n",
       "      <td>52.831080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55420</td>\n",
       "      <td>38.803160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55421</td>\n",
       "      <td>19.287067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55422</td>\n",
       "      <td>7.663286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55423</td>\n",
       "      <td>79.790836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55424</td>\n",
       "      <td>4.567584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55425</td>\n",
       "      <td>7.357980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55426</td>\n",
       "      <td>9.718460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55427</td>\n",
       "      <td>9.135452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55428</td>\n",
       "      <td>33.626282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55429</td>\n",
       "      <td>6.057884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36902</th>\n",
       "      <td>92302</td>\n",
       "      <td>39.752682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36903</th>\n",
       "      <td>92303</td>\n",
       "      <td>15.505526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36904</th>\n",
       "      <td>92304</td>\n",
       "      <td>32.515067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36905</th>\n",
       "      <td>92305</td>\n",
       "      <td>1.827381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36906</th>\n",
       "      <td>92306</td>\n",
       "      <td>26.286076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36907</th>\n",
       "      <td>92307</td>\n",
       "      <td>18.685744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36908</th>\n",
       "      <td>92308</td>\n",
       "      <td>12.389853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36909</th>\n",
       "      <td>92309</td>\n",
       "      <td>69.914107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36910</th>\n",
       "      <td>92310</td>\n",
       "      <td>6.268615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36911</th>\n",
       "      <td>92311</td>\n",
       "      <td>34.380698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36912</th>\n",
       "      <td>92312</td>\n",
       "      <td>16.301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36913</th>\n",
       "      <td>92313</td>\n",
       "      <td>14.476848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36914</th>\n",
       "      <td>92314</td>\n",
       "      <td>6.447430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36915</th>\n",
       "      <td>92315</td>\n",
       "      <td>41.167905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36916</th>\n",
       "      <td>92316</td>\n",
       "      <td>5.460317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36917</th>\n",
       "      <td>92317</td>\n",
       "      <td>44.118841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36918</th>\n",
       "      <td>92318</td>\n",
       "      <td>2.075068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36919</th>\n",
       "      <td>92319</td>\n",
       "      <td>40.292864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36920</th>\n",
       "      <td>92320</td>\n",
       "      <td>11.109171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36921</th>\n",
       "      <td>92321</td>\n",
       "      <td>2.445254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36922</th>\n",
       "      <td>92322</td>\n",
       "      <td>11.847770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36923</th>\n",
       "      <td>92323</td>\n",
       "      <td>75.588186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36924</th>\n",
       "      <td>92324</td>\n",
       "      <td>24.200242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36925</th>\n",
       "      <td>92325</td>\n",
       "      <td>21.841179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36926</th>\n",
       "      <td>92326</td>\n",
       "      <td>42.412035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36927</th>\n",
       "      <td>92327</td>\n",
       "      <td>22.537763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36928</th>\n",
       "      <td>92328</td>\n",
       "      <td>4.132156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36929</th>\n",
       "      <td>92329</td>\n",
       "      <td>15.262812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36930</th>\n",
       "      <td>92330</td>\n",
       "      <td>2.144172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36931</th>\n",
       "      <td>92331</td>\n",
       "      <td>66.426222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Greater_Risk_Probability\n",
       "0           55400                 59.826614\n",
       "1           55401                 29.004116\n",
       "2           55402                 55.252582\n",
       "3           55403                 18.244876\n",
       "4           55404                  5.883608\n",
       "5           55405                 48.089758\n",
       "6           55406                  8.856620\n",
       "7           55407                  5.165112\n",
       "8           55408                 18.210373\n",
       "9           55409                  8.622976\n",
       "10          55410                 12.271101\n",
       "11          55411                  2.896477\n",
       "12          55412                  7.900046\n",
       "13          55413                  6.758299\n",
       "14          55414                 34.516844\n",
       "15          55415                 85.055578\n",
       "16          55416                 44.791375\n",
       "17          55417                 26.193295\n",
       "18          55418                 14.011161\n",
       "19          55419                 52.831080\n",
       "20          55420                 38.803160\n",
       "21          55421                 19.287067\n",
       "22          55422                  7.663286\n",
       "23          55423                 79.790836\n",
       "24          55424                  4.567584\n",
       "25          55425                  7.357980\n",
       "26          55426                  9.718460\n",
       "27          55427                  9.135452\n",
       "28          55428                 33.626282\n",
       "29          55429                  6.057884\n",
       "...           ...                       ...\n",
       "36902       92302                 39.752682\n",
       "36903       92303                 15.505526\n",
       "36904       92304                 32.515067\n",
       "36905       92305                  1.827381\n",
       "36906       92306                 26.286076\n",
       "36907       92307                 18.685744\n",
       "36908       92308                 12.389853\n",
       "36909       92309                 69.914107\n",
       "36910       92310                  6.268615\n",
       "36911       92311                 34.380698\n",
       "36912       92312                 16.301474\n",
       "36913       92313                 14.476848\n",
       "36914       92314                  6.447430\n",
       "36915       92315                 41.167905\n",
       "36916       92316                  5.460317\n",
       "36917       92317                 44.118841\n",
       "36918       92318                  2.075068\n",
       "36919       92319                 40.292864\n",
       "36920       92320                 11.109171\n",
       "36921       92321                  2.445254\n",
       "36922       92322                 11.847770\n",
       "36923       92323                 75.588186\n",
       "36924       92324                 24.200242\n",
       "36925       92325                 21.841179\n",
       "36926       92326                 42.412035\n",
       "36927       92327                 22.537763\n",
       "36928       92328                  4.132156\n",
       "36929       92329                 15.262812\n",
       "36930       92330                  2.144172\n",
       "36931       92331                 66.426222\n",
       "\n",
       "[36932 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Patient_ID'] = test['Patient_ID']\n",
    "submission['Greater_Risk_Probability'] = preds\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
